{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download the datasets from the course website, unzip (7z program) and load it with pandas.\n",
    "### (Hint: df = pd.read_json(\"..json\", orient='records', lines=True)\n",
    "### Use the following site from arxiv (https://arxiv.org/category_taxonomy) to taxonomize the documents into 5 categories: {0:'Computer Science', 1:'Mathematics', 2:'Statistics', 3:'Economics', 4:'EESS'}. This will constitute the ground truth. To create labels, use the first category entry.\n",
    "### (Hint: Use the regular expression re.search(r'^([\\w\\-]+)', cat.split(' ')[0]).group(1) on the categories column. Check: [110347, 130726, 13920, 924, 7252] and [111091, 130287, 13672, 871, 7249] in training and testing sizes, respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import re\n",
    "\n",
    "\n",
    "# Load the training and testing datasets\n",
    "df_train = pd.read_json(\"arxiv_training.json\", orient='records', lines=True)\n",
    "df_test = pd.read_json(\"arxiv_testing.json\", orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(cat):\n",
    "    sant = re.search(r'^([\\w\\-]+)', cat.split(' ')[0]).group(1)\n",
    "    return sant if sant in {'cs', 'stat', 'math', 'econ', 'eess'} else 'NA'\n",
    "\n",
    "df_train['categories'] = df_train['categories'].apply(sanitize)\n",
    "df_test['categories'] = df_test['categories'].apply(sanitize)\n",
    "\n",
    "df_train['update_date'] = pd.to_datetime(df_train['update_date'])\n",
    "df_test['update_date'] = pd.to_datetime(df_test['update_date'])\n",
    "\n",
    "df_train = df_train[(df_train['categories'] != 'NA') & (df_train['update_date'].dt.year >= 2010)]\n",
    "df_test = df_test[(df_test['categories'] != 'NA') & (df_test['update_date'].dt.year >= 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'math': 149465,\n",
       "          'cs': 115106,\n",
       "          'stat': 14305,\n",
       "          'eess': 7285,\n",
       "          'econ': 903}),\n",
       " Counter({'math': 148482,\n",
       "          'cs': 116397,\n",
       "          'stat': 14251,\n",
       "          'eess': 7217,\n",
       "          'econ': 892}))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(df_train['categories']),Counter(df_test['categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. [30 pts] Classify the documents and report testing accuracy (confusion matrix?).\n",
    "### (Hint: Use TfidfVectorizer with a Pipeline. If you use a random forest make sure the max_depth parameter is reasonable, i.e. <30, to make sure it finishes faster. Any classifier you use has to know how to deal with sparse matrices.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into training and testing sets\n",
    "X_train, y_train = df_train['abstract'], df_train['categories']\n",
    "X_test, y_test = df_test['abstract'], df_test['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.8971588119997632\n",
      "Confusion Matrix:\n",
      "[[106964     21   1141   6762   1509]\n",
      " [   363    138      0    181    210]\n",
      " [  5366      3   1288    476     84]\n",
      " [  5490     17    140 141403   1432]\n",
      " [  4426     32     54   1833   7906]]\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with CountVectorizer, TfidfTransformer, and a MultinomialNB classifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler  # Example data preprocessing step\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "N_FEATURES=10\n",
    "pipeline = Pipeline([('scaler', TfidfVectorizer()),  # Standardize the data\n",
    "    ('classifier', LogisticRegression(max_iter=100)),\n",
    "                   ])\n",
    "pipeline.fit(X_train, y_train)\n",
    "# Predict the categories on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Testing Accuracy:\", accuracy)\n",
    "\n",
    "# Generate and display the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7928902412276885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          cs       0.78      0.76      0.77    116397\n",
      "        econ       0.00      0.00      0.00       892\n",
      "        eess       0.19      0.00      0.00      7217\n",
      "        math       0.80      0.94      0.86    148482\n",
      "        stat       0.63      0.02      0.03     14251\n",
      "\n",
      "    accuracy                           0.79    287239\n",
      "   macro avg       0.48      0.34      0.33    287239\n",
      "weighted avg       0.77      0.79      0.76    287239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State the class with the least performance. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class with the least performance is econ and eess. The reason for this is largely due to two things. The first thing is that eess and econ both contain the smallest number of entries, which can lead to a less accurate definer. The next issue is that the classifier is overwhelmingly skewed towards falsely identifying eess and econ as a computer science paper. This is likely due to the fact that a large number of papers hee ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. [30 pts] Apply POS processing and pick only nouns as tokens (i.e., <NN>+, <NNP>+, etc.).\n",
    "### Repeat and report any classification improvement in your pipeline in (2.).\n",
    "### Can you suggest other tags to improve the pipeline?\n",
    "### (Note that POS will take a long time (up to 1 hour) in this large dataset and suggest saving the tokens in another DataFrame. In addition, once tokenized and stored one can use TfidfVectorizer(tokenizer=lambda x:x, lowercase=False) to work on the tokenized list directly. Make sure you test your tagger on small datasets first. Suggest PerceptronTagger())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_df_train=df_train['abstract']\n",
    "cat_df_train=df_train['categories']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test=abs_df_train.iloc[0:20]\n",
    "test_cat=cat_df_train.iloc[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(text):\n",
    "    # Tokenize the text using a regular expression tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Perform POS tagging on the tokens using the PerceptronTagger\n",
    "    pos_tags = PerceptronTagger().tag(tokens)\n",
    "    \n",
    "    # Extract nouns (NN, NNS, NNP, NNPS)\n",
    "    nouns = [token for token, pos in pos_tags if pos in ['NN', 'NNS', 'NNP', 'NNPS']]\n",
    "    \n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tag import PerceptronTagger\n",
    "df_nouns = pd.DataFrame()\n",
    "df_nouns['nouns'] = test\n",
    "\n",
    "# Save this new DataFrame for future use, as POS tagging can be time-consuming\n",
    "df_nouns.to_csv('nouns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the saved nouns DataFrame\n",
    "df_nouns = pd.read_csv('nouns.csv')\n",
    "\n",
    "# Create a TfidfVectorizer with custom tokenizer\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "\n",
    "# Fit and transform the nouns to obtain the TF-IDF features\n",
    "\n",
    "act_test=df_train['categories'].iloc[0:20].apply(extract_nouns)\n",
    "\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_nouns['nouns'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a target variable 'labels' in your original DataFrame\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
