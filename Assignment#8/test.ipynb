{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Documents = [reuters.raw(fid) for fid in reuters.fileids()]\n",
    "\n",
    "# Categories are list of lists since each news may have more than 1 category\n",
    "Categories = [reuters.categories(fid) for fid in reuters.fileids()]\n",
    "CategoriesList = [_ for sublist in Categories for _ in sublist]\n",
    "CategoriesSet = np.unique(CategoriesList)\n",
    "\n",
    "print(f'N documents= {len(Documents):d}, K unique categories= {len(CategoriesSet):d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Check the categories and their counts\n",
    "counts = Counter(CategoriesList)\n",
    "counts = sorted(counts.items(), key=lambda pair: pair[1], reverse=True)\n",
    "\n",
    "print(counts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the news category list\n",
    "yCategories = [_[0] for _ in counts[:5]]\n",
    "yCategories += ['other']\n",
    "\n",
    "# Sanity check\n",
    "print(f'K categories for classification= {len(yCategories):d} categories, {yCategories}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a category for each news text, including 'other'\n",
    "yCat = []\n",
    "for cat in Categories:\n",
    "    bFound = False\n",
    "    for _ in yCategories:\n",
    "        if _ in cat:\n",
    "            yCat += [_]\n",
    "            bFound = True\n",
    "            break  # So we add only one category for a news text\n",
    "    if not bFound:\n",
    "        yCat += ['other']\n",
    "        \n",
    "# Sanity check\n",
    "print(f'N target categories={len(yCat):d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numerical np.array which sklearn requires\n",
    "ydocs = np.array([yCategories.index(_) for _ in yCat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFold will require indexable data structure\n",
    "Docs = pd.Series(Documents)\n",
    "Categories = pd.Series(yCat)\n",
    "\n",
    "# Sanity check\n",
    "print(Categories[0],'-->',Docs[0][:150],'\\n',\n",
    "      Categories[1],'-->',Docs[1][:150],'\\n',\n",
    "      Categories[2],'-->',Docs[2][:150])\n",
    "\n",
    "# Size of the problem\n",
    "print(f'N={len(Docs)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def kfold_eval_docs(_clf, _Xdocs, _ydocs):\n",
    "    # Need indexable data structure\n",
    "    accuracies = []\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "    for train_index, test_index in kf.split(_Xdocs, _ydocs):\n",
    "        _clf.fit(_Xdocs[train_index], _ydocs[train_index])\n",
    "        y_pred = _clf.predict(_Xdocs[test_index])\n",
    "        accuracies += [accuracy_score(_ydocs[test_index], y_pred)]\n",
    "\n",
    "    return np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of the dataset matrix X for this Tf-Idf feature extraction - raw number of features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_tfidf = TfidfVectorizer().fit_transform(Documents)\n",
    "print(f'N data points= {X_tfidf.shape[0]}, M features= {X_tfidf.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Docs.items(),Categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def kfold_eval_docs(_clf, _Xdocs, _ydocs):\n",
    "    # Need indexable data structure\n",
    "    accuracies = []\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "    for train_index, test_index in kf.split(_Xdocs, _ydocs):\n",
    "        _clf.fit(_Xdocs[train_index], _ydocs[train_index])\n",
    "        y_pred = _clf.predict(_Xdocs[test_index])\n",
    "        accuracies += [accuracy_score(_ydocs[test_index], y_pred)]\n",
    "\n",
    "    return np.array(accuracies)\n",
    "\n",
    "N_FEATURES=1\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_lin = Pipeline([('clf', LinearSVC(class_weight='balanced')),('tfidf',TfidfTransformer()),\n",
    "                   ])\n",
    "acc = kfold_eval_docs(svm_lin, Docs, Categories)\n",
    "print(f'Support Vector Machine (linear SVC) CV accuracy={np.mean(acc):.3f} {np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES=1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
